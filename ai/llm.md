Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand and generate human language

They are built on deep learning techniques, specifically using a type of neural network architecture known as transformer models

The term 'Large' refers to the extensive datasets on which these models are trained

### inference

- process of generating responses or predictions based on the input provided by the user

- process
  1. input reception: the model receives a prompt or query
  2. tokenization: the input is broken down into tokens, which are the smallest units of meaning that the model can understand
  3. response generation: using complex probabilistic computations, the model generates a response by selecting the most likely next
     token based on the learned patterns
